# 03.5 - Common DAX Anti-patterns

## Overview

DAX anti-patterns are common coding practices that appear to work correctly but cause poor performance, maintenance challenges, or unexpected results. These patterns often emerge when developers apply SQL or Excel thinking to DAX without understanding how the DAX formula engine and storage engine interact. This topic identifies the most frequent DAX anti-patterns observed in healthcare analytics implementations, explains why they're problematic, and provides optimized alternatives drawn from SQLBI best practices and AbsoluteCare's assessment findings.

## Key Principles

- **Avoid Calculated Columns for Aggregatable Data**: Calculated columns consume memory and recalculate during refresh. Use measures for aggregatable values (sums, counts, averages) and calculated columns only for non-aggregatable attributes (categorization, grouping).

- **Never Use Iterators on Large Tables Without Need**: SUMX, AVERAGEX, and other iterators evaluate row-by-row. When simple aggregation functions (SUM, AVERAGE, COUNT) work, use them instead - they're optimized for columnar storage.

- **Eliminate Repeated Logic with Variables**: Repeating the same expression multiple times forces the engine to recalculate it multiple times. Use VAR to calculate once and reference multiple times.

- **Avoid Filter Context Manipulation Without Understanding Context Transition**: Using CALCULATE, ALL, ALLSELECTED incorrectly leads to unexpected results and poor performance. Understand filter context, row context, and context transition before using these functions.

- **Stop Using Implicit Measures**: Dragging fields to visuals creates implicit measures (auto-generated SUM, COUNT). These are hard to maintain, rename, and format. Create explicit measures with clear names and formatting.

## Practical Example

### Example 1: Calculated Column vs Measure for Aggregatable Data

**L Anti-pattern: Calculated Column for Aggregatable Value**

```dax
// CALCULATED COLUMN in FactEncounters table (BAD)
TotalCharge = FactEncounters[Quantity] * FactEncounters[UnitPrice]
```

**Why this is bad**:
- Calculated column stores the result for every row (5 million rows = 5 million stored values)
- Consumes memory in the semantic model
- Recalculates during every data refresh
- Doesn't automatically aggregate when used in visuals (still requires SUM in visual)

** Correct: Measure for Aggregatable Value**

```dax
// MEASURE (GOOD)
Total Charge =
SUMX(
    FactEncounters,
    FactEncounters[Quantity] * FactEncounters[UnitPrice]
)
```

**Why this works**:
- Calculates on-demand when visual needs it
- No storage required (calculates from Quantity and UnitPrice columns)
- Automatically aggregates at correct granularity
- Better performance in most scenarios

**Even Better with Pre-Calculated Column When Needed**:

If you truly need a calculated column (e.g., for row-level filtering), calculate it in Power Query or source database:

```powerquery
// Power Query M code
= Table.AddColumn(FactEncounters, "TotalCharge",
    each [Quantity] * [UnitPrice], Currency.Type)
```

**Why this is best**: Calculated in Power Query compresses better in VertiPaq, supports query folding if in database, and separates ETL from semantic model logic.

### Example 2: Avoiding Unnecessary Iterators

**L Anti-pattern: Using SUMX Where SUM Works**

```dax
// Using SUMX unnecessarily (BAD)
Total Encounters = SUMX(FactEncounters, FactEncounters[EncounterCount])
```

**Why this is bad**:
- SUMX iterates row-by-row through the table (millions of iterations)
- Much slower than columnar SUM operation
- No benefit over simple SUM for this use case

** Correct: Simple SUM Function**

```dax
// Using SUM (GOOD)
Total Encounters = SUM(FactEncounters[EncounterCount])
```

**Why this works**:
- Leverages columnar storage engine optimization
- 10-100x faster than SUMX for simple aggregation
- Cleaner, more readable code

**When SUMX IS Appropriate**:

```dax
// SUMX needed when calculation happens per row (CORRECT USE)
Total Revenue =
SUMX(
    FactEncounters,
    FactEncounters[Quantity] * RELATED(DimService[UnitPrice])
)
```

This requires SUMX because each row needs a lookup to DimService for UnitPrice before multiplication.

### Example 3: Using Variables to Eliminate Redundant Calculations

**L Anti-pattern: Repeating Calculations**

```dax
// Without variables (BAD)
Prior Year Variance % =
DIVIDE(
    SUM(FactEncounters[ChargeAmount]) - CALCULATE(SUM(FactEncounters[ChargeAmount]), SAMEPERIODLASTYEAR(DimDate[Date])),
    CALCULATE(SUM(FactEncounters[ChargeAmount]), SAMEPERIODLASTYEAR(DimDate[Date]))
)
```

**Why this is bad**:
- `SUM(FactEncounters[ChargeAmount])` calculated 2 times
- `CALCULATE(SUM(...), SAMEPERIODLASTYEAR(...))` calculated 2 times
- DAX engine recalculates each expression every time it appears
- Harder to read and maintain

** Correct: Using Variables**

```dax
// With variables (GOOD) - Assessment Recommendation
Prior Year Variance % =
VAR CurrentPeriod = SUM(FactEncounters[ChargeAmount])
VAR PriorPeriod = CALCULATE(
    SUM(FactEncounters[ChargeAmount]),
    SAMEPERIODLASTYEAR(DimDate[Date])
)
VAR Variance = CurrentPeriod - PriorPeriod
RETURN
    DIVIDE(Variance, PriorPeriod)
```

**Why this works**:
- Each calculation performed once and stored in variable
- 30-50% performance improvement for complex measures
- Much easier to debug (can test each VAR separately in DAX Studio)
- Self-documenting code (variable names explain logic)
- Assessment finding: AbsoluteCare measures lacked variable usage

### Example 4: Implicit Measures (Never Use)

**L Anti-pattern: Using Implicit Measures**

Dragging `FactEncounters[ChargeAmount]` field directly to a visual creates:
```dax
Sum of ChargeAmount  // Auto-generated implicit measure
```

**Why this is bad**:
- Name is unprofessional ("Sum of ChargeAmount" appears in tooltips, exported data)
- No control over formatting (currency, decimals)
- Can't add error handling (DIVIDE vs / operator)
- Can't be referenced by other measures (not reusable)
- Hard to maintain as business logic evolves
- Assessment finding: Teams using implicit measures struggled with consistency

** Correct: Explicit Measure**

```dax
// Create explicit measure (GOOD)
Total Charges =
VAR ChargeTotal = SUM(FactEncounters[ChargeAmount])
RETURN
    IF(
        ISBLANK(ChargeTotal),
        BLANK(),
        ChargeTotal
    )
```

Then format the measure:
- Name: "Total Charges"
- Format: Currency, $ English (United States), 0 decimals
- Description: "Total charge amount for encounters in filter context"

**Why this works**:
- Professional naming in visuals and tooltips
- Consistent formatting across all visuals
- Can add business logic (error handling, conditional calculations)
- Reusable in other measures (measure chaining)

### Example 5: Measure Chaining (Modular, Reusable Measures)

**L Anti-pattern: Copy-Paste Measure Logic**

```dax
// Separate measures with repeated logic (BAD)
Total Encounters = SUM(FactEncounters[EncounterCount])

Encounters YoY % =
DIVIDE(
    SUM(FactEncounters[EncounterCount]) - CALCULATE(SUM(FactEncounters[EncounterCount]), SAMEPERIODLASTYEAR(DimDate[Date])),
    CALCULATE(SUM(FactEncounters[EncounterCount]), SAMEPERIODLASTYEAR(DimDate[Date]))
)

Encounters vs Target % =
DIVIDE(
    SUM(FactEncounters[EncounterCount]),
    CALCULATE(SUM(FactEncounters[EncounterCount]), ALL(DimProvider))
)
```

**Problem**: `SUM(FactEncounters[EncounterCount])` repeated in 3 measures. If business logic changes (e.g., filter to only include "Completed" encounters), you must update 3 places.

** Correct: Measure Chaining (Build on Base Measures)**

```dax
// Base measure
Total Encounters = SUM(FactEncounters[EncounterCount])

// Build on base measure (GOOD)
Encounters Prior Year =
CALCULATE(
    [Total Encounters],  // Reference base measure
    SAMEPERIODLASTYEAR(DimDate[Date])
)

// Build on both measures
Encounters YoY % =
VAR CurrentYear = [Total Encounters]
VAR PriorYear = [Encounters Prior Year]
RETURN
    DIVIDE(CurrentYear - PriorYear, PriorYear)

// Another measure building on base
Encounters vs Target % =
VAR ProviderValue = [Total Encounters]
VAR OverallAverage = CALCULATE([Total Encounters], ALL(DimProvider))
RETURN
    DIVIDE(ProviderValue, OverallAverage)
```

**Why this works**:
- Change business logic once in `[Total Encounters]`, all dependent measures update
- Easier to test and debug (verify base measure correctness first)
- Self-documenting (measure names explain calculation components)
- Consistent results (no copy-paste errors)
- Assessment recommendation: Build modular, reusable measures

## Common Pitfalls

### L Pitfall 1: Using ALL() When You Mean ALLSELECTED()

**Description**: Using ALL(DimDate[Year]) to remove filters from Year column removes ALL filters including slicer selections, not just visual-level filters.

**Impact**: "% of Total" calculations show wrong percentages when users filter with slicers. User filters Year = 2024 with slicer, but ALL() removes it, showing % of all years instead of % of 2024.

**Fix**:
```dax
// WRONG: Removes all filters including slicers
Pct of Total Wrong =
DIVIDE(
    [Total Encounters],
    CALCULATE([Total Encounters], ALL(DimProvider))
)

// CORRECT: Respects slicer selections
Pct of Total Correct =
DIVIDE(
    [Total Encounters],
    CALCULATE([Total Encounters], ALLSELECTED(DimProvider))
)
```

### L Pitfall 2: Not Handling BLANK() and Division by Zero

**Description**: Using division operator (/) instead of DIVIDE function, causing errors when denominator is zero or blank.

**Impact**: Visuals show "Error" or incorrect results when no data exists for filter context. Reports fail for edge cases like new providers with no encounters yet.

**Fix**:
```dax
// WRONG: Causes errors
Avg Charge = SUM(FactEncounters[ChargeAmount]) / SUM(FactEncounters[EncounterCount])

// CORRECT: Handles division by zero gracefully
Avg Charge =
DIVIDE(
    SUM(FactEncounters[ChargeAmount]),
    SUM(FactEncounters[EncounterCount]),
    BLANK()  // Return BLANK() instead of error when divisor is zero
)
```

### L Pitfall 3: Using FILTER on Large Tables Instead of KEEPFILTERS

**Description**: Using FILTER(ALL(Table), condition) on fact tables with millions of rows instead of more efficient filter functions.

**Impact**: FILTER iterates every row in the table to evaluate the condition. On a 5M row fact table, this can take seconds. More efficient functions like KEEPFILTERS, TREATAS, or native CALCULATE filters exist.

**Fix**:
```dax
// WRONG: Iterates all 5M rows
High Value Encounters =
CALCULATE(
    [Total Encounters],
    FILTER(ALL(FactEncounters), FactEncounters[ChargeAmount] > 1000)
)

// BETTER: Use CALCULATE filter arguments (if possible)
High Value Encounters =
CALCULATE(
    COUNTROWS(FactEncounters),
    FactEncounters[ChargeAmount] > 1000
)

// OR: Use KEEPFILTERS to intersect with existing filter
High Value Encounters =
CALCULATE(
    [Total Encounters],
    KEEPFILTERS(FactEncounters[ChargeAmount] > 1000)
)
```

## Healthcare Context

### Performance Considerations

DAX anti-patterns directly impact the <5 second clinical workflow SLA:

**Measured Impact at AbsoluteCare**:
- Measures with repeated calculations (no variables): 800-2000ms execution time
- After adding variables: 250-500ms execution time (70% improvement)
- Replacing calculated columns with measures: 40% reduction in model size, faster refresh

**Optimization Priority**:
1. Fix measures that Performance Analyzer shows >500ms
2. Eliminate implicit measures from all reports
3. Add variables to measures with repeated logic
4. Replace calculated columns with measures or Power Query columns

### Print/Mobile Implications

**Faster Measures = Faster Everything**:
- Optimized DAX improves both interactive and print subscription performance
- Print subscriptions timeout if measures take too long to calculate
- Mobile devices benefit even more from efficient DAX (limited processing power)

**Consistent Formatting**:
- Explicit measures with defined formatting ensure printed reports show proper currency symbols, decimal places
- Implicit measures cause inconsistent formatting between screen and print

### Compliance Notes

**Row-Level Security Performance**: Anti-patterns in DAX measures used with RLS filters compound performance problems. A slow measure (1 second) with RLS filtering 10 providers becomes 10 seconds. Optimize measures before adding RLS.

**Audit Complexity**: Implicit measures and copy-pasted logic make auditing difficult. Explicit, modular measures with clear names facilitate compliance reviews and documentation.

## Learn More

### Official Documentation
- [DAX Function Reference](https://learn.microsoft.com/en-us/dax/dax-function-reference) - Official Microsoft DAX documentation
- [Best Practices for DAX](https://learn.microsoft.com/en-us/power-bi/guidance/dax-avoid-avoid-filter) - Microsoft guidance on DAX optimization

### Expert Resources
- [DAX Patterns](https://www.daxpatterns.com/) - SQLBI collection of common DAX patterns and anti-patterns
- [The Definitive Guide to DAX (2nd Edition)](https://www.sqlbi.com/books/the-definitive-guide-to-dax-2nd-edition/) - Marco Russo & Alberto Ferrari comprehensive DAX book
- [Optimizing DAX Performance](https://www.sqlbi.com/articles/optimizing-dax-performance/) - SQLBI performance optimization techniques

### Video Content
- [DAX Anti-Patterns to Avoid](https://www.youtube.com/c/SQLBI) - SQLBI video series on common mistakes
- [Variables in DAX](https://www.youtube.com/c/GuyinaCube) - Guy in a Cube tutorial on using VAR effectively

### Related Topics
- [03.1 - Measure Organization & Naming Conventions](03.1%20-%20Measure%20Organization%20&%20Naming%20Conventions.md) - Organizing measures for maintainability
- [03.2 - Variables & Code Readability](03.2%20-%20Variables%20&%20Code%20Readability.md) - Deep dive on variable usage
- [03.3 - Filter Context & Context Transition](03.3%20-%20Filter%20Context%20&%20Context%20Transition.md) - Understanding context for correct DAX
- [02.4 - Performance Analyzer Workflow](../02%20-%20Performance%20Optimization%20&%20Query%20Design/02.4%20-%20Performance%20Analyzer%20Workflow.md) - Identifying slow DAX measures
- [01.4 - Calculated Columns vs Measures](../01%20-%20Data%20Architecture%20&%20Semantic%20Modeling/01.4%20-%20Calculated%20Columns%20vs%20Measures.md) - When to use each

---

*Last updated: October 2025*
